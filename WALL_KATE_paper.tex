\documentclass[review]{siamart251216}

% 1. Preamble and packages
\usepackage{amsfonts, amsmath, amssymb, amsbsy}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algorithmic}
\ifpdf%
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi
\usepackage{amsopn}
\DeclareMathOperator{\diag}{diag}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{todonotes}
\usepackage{caption}
\usepackage{float}

\DeclareCaptionType{equ}[Equation][List of Equations]
%\captionsetup[equ]{labelformat=empty}

% 1.5 Macros 
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\bigOh}{\mathcal{O}}
\renewcommand{\vec}[1]{{{\mathbf{#1}}}}
\renewcommand{\t}{{\vec  t }}
\newcommand{\s}{{\vec  s}}
\renewcommand{\u}{{\vec  u }}
\renewcommand{\v}{{\vec  v }}
\newcommand{\f}{{\vec  f }}
\newcommand{\zero}{{\vec  0 }}
\newcommand{\A}{{A }}
\newcommand{\offd}{{B}}
\newcommand{\Hank}{{ H }}
\newcommand{\DST}{{ S }}
\newcommand{\Tau}{T}
\newcommand{\ptau}{{\bm{\tau}}}
\newcommand{\Sq}{{S_Q}} 



% 2. Paper title
\newcommand{\TheTitle}{%
  Reviving Circulant Preconditioners for Adaptive Mesh Refinement
}

% 2.5. Short title for running heads (if needed)
\newcommand{\TheShortTitle}{%
  \TheTitle
}

% 3. Student Name
\newcommand{\TheName}{%
 K. Wall
}

% 4. Student Address
\newcommand{\TheAddress}{%
  Tufts University,
  (\email{kate.wall@tufts.edu}, \url{https://katejeanw.github.io/}).
}

% 5. Acknowledge funding or other resources
\newcommand{\TheFunding}{%
  This work was funded by NSF\@.
}

% 6. Collaborators, such as advisor or research collaborators
\newcommand{\TheCollaborators}{%
  James Adler,
  Xiaozhe Hu,
  Misha Kilmer
}

% ---------------------------------------------
% ---------------------------------------------
\author{\TheName\thanks{\TheAddress}}
\title{{\TheTitle}\thanks{\TheFunding}}
\headers{\TheShortTitle}{\TheName}
\ifpdf%
\hypersetup{%
  pdftitle={\TheTitle},
  pdfauthor={\TheName}
}
\fi

\begin{document}

\maketitle

\begin{center}
In collaboration with:
  {\TheCollaborators}
\end{center}
\vspace{1cm}
% ---------------------------------------------
% ---------------------------------------------

\begin{abstract}
We present a preconditioner for solving fractional partial differential equations (PDEs) on an adaptive mesh. Adaptive refinement of the problem domain results in a stiffness matrix with Toeplitz blocks along the main diagonal, while the fractional PDE yields a dense stiffness matrix, where off-diagonal blocks are stored as low-rank approximations. Our preconditioner utilizes ideas from the circulant preconditioner of Chan and Strang [SIAM Journal on Scientific Computing, 1989], which takes advantage of the Toeplitz blocks on the diagonal and also accounts for the low-rank nature of the off-diagonal blocks. We demonstrate its effectiveness at accelerating convergence for our systems and emphasize its efficient application. This work presents theoretical results about the spectral clustering of the preconditioned system. In order to prove these results, special consideration is taken on how the low-rank blocks perturb the eigenvalues of the Toeplitz block-diagonal system. Numerical tests for various fractional orders are used to inspect any assumptions and validate our results.
\end{abstract}




\begin{keywords}
  % 7. Keywords that describe the paper
  Preconditioner, Adaptive Refinement, Toeplitz, Circulant, DST, DCT
\end{keywords}

	


\section{Introduction} 
% Availabilitty of Xiaozhe's code / stiffness matrices 

There has long been interest in solving Toeplitz linear systems efficiently. A matrix $A$ is called Toeplitz if $a_{ij} = a_{i-j}$, in other words, $A$ has constant diagonals. Arbitrary $n \times n$ matrices have up to $n^2$ unique entries and are solved directly by traditional techniques in $\bigOh(n^3)$ time. Since a Toeplitz matrix has just at most $2n-1$ unique entries, we may expect to be able to solve it in $\bigOh (n^2)$ time. This is indeed the case via techniques such as Levinson's algorithm \cite{Levinson}. Even this improvement, however, is infeasible for large systems. Instead we turn to iterative Krylov and multigrid methods. For these methods we can still take advantage of Toeplitz structure by using circulant preconditioners. 

A circulant matrix is a Toeplitz matrix, that additionally has the ``wrap-around'' property where the last entry each row is the first entry of the subsequent row. 

\begin{equ}[H]
	\begin{equation}
	T = \begin{pmatrix}
		t_0  &  t_{-1} & \cdots & t_{-(n-1)} \\
		t_{1} & t_0 & \cdots & t_{-(n-2)} \\
		\vdots & \vdots & \ddots & \vdots \\
		t_{n-1} & t_{n-2} & \cdots & t_0 
	\end{pmatrix} 
	\hspace{.15 in}
	C = \begin{pmatrix}
		c_0 & c_1 & \cdots & c_{n-1} \\
		c_{n-1} & c_0 & \cdots & c_{n-2} \\
		\vdots & \vdots & \ddots & \vdots \\
		c_{1} & c_{2} & \cdots & c_0 
		\end{pmatrix}
\end{equation}
\caption{$T$ is a Toeplitz matrix and $C$ is circulant.}
\end{equ}

Toeplitz matrices commonly arise in PDE discretization, signal processing, and control theory. Often the Toeplitz matrices are also symmetric positive definite (SPD). Given an SPD Toeplitz system $Tx = b$, the idea introduced by Strang and Chan is to use certain circulant preconditioners $C$ so that $C^{-1}Tx = C^{-1}b$ is solved in fewer iterations \cite{Chan_Strang}.

We leverage this idea to build a preconditioner for stiffness matrices generated from the adaptive finite element method (AFEM) for fractional PDEs. In this setting the problem is discretized on a nonuniform mesh, and the resulting stiffness matrix is dense. In the usual finite element method (FEM) setting an uniform mesh results in a Toeplitz stiffness matrix. In the adaptive setting, after an initial solve on a uniform grid, the error on each element is estimated and the elements with largest error are refined via bisection. It is often the case that neighboring elements are refined the same number of times. So although the mesh is not globally uniform, there are areas of local uniformity. To build an effective preconditioner, we will take advantage of these locally uniform areas and their corresponding Toeplitz blocks in the stiffness matrix. 
% application for fractional pdes
% similar systems result from mixed precision 
\todo[inline]{TODO: citations for facts about FEM and Toeplitz matrices}

Although dense, the stiffness matrix can be effectively stored as a hierarchical matrix ($\mathcal{H}$-matrix). Due to weaker interaction between elements that are further apart in the domain, off-diagonal blocks are well-suited for low rank approximation. (See \cite{Xiaozhe} for more stiffness matrix details.) The low rank representation makes for fast computations, but complicates both the implementation of the preconditioner and the spectral clustering of the preconditioned system. 

% These preconditioners can be thought of as coming from Kernels of displacement operators. Cite Kalaith and Chan-Yeung.

In this paper we investigate how to precondition such systems using circulant matrices. Our investigation is focused on $\mathcal{H}$-matrices as in \cite{Xiaozhe}, but the same methods could be used on any matrix with Toeplitz blocks on the diagonal. We prove the preconditioned system has eigenvalues clustered around 1 and demonstrate numerical results with superlinear convergence. 

We emphasize that our unique contributions are:
\begin{itemize}
	\item building circulant preconditioners for adaptive meshes 
	\item proving the preconditioned system has eigenvalues clustered around 1
	\item something else? numerical results? dealing with low-rank blocks?
\end{itemize}

% overview of subsequent sections?

\section{Background}
%% FEM and matrix structure 
To understand the need for our preconditioner, we must give a bit more detail about AFEM. We restrict our attention to problems on a one-dimensional domain, $[a,b]$ with the discretization $a = x_0, x_1, \dots, x_n = b$. Often FEM is  done on a uniform mesh, that is each element $[x_i, x_{i+1}]$ is size $x_{i+1}- x_i$ for all $0 \leq i \leq n-1$.

% brief proof uniform mesh gives toeplitz?
If the mesh is not fine enough to give the desired accuracy, one approach is to increase the number of elements, $n$. While this approach preserves uniformity, it usually requires recomputing the stiffness matrix entirely. Alternatively, if the level of refinement gives sufficiently small error for some parts of the domain, we can leave those unchanged and only refine in areas of larger error. This approach allows us to take advantage of computations that have already been performed, but the mesh is no longer uniform. 

In practice we find that adjacent elements are often refined to the same level, so a group of elements forms a locally uniform mesh. Since uniform meshes give rise to SPD Toeplitz systems, we can see that if we formed the stiffness matrix for just a locally uniform subdomain we would have an SPD Toeplitz matrix. So wherever there are adjacent elements of the same size we can find a corresponding Toeplitz block on the main diagonal of our stiffness matrix, $\A$. The size of this block depends on how many adjacent elements are the same size. We have also observed that the boundary of the domain almost always requires the greatest level of refinement. In general we have larger Toeplitz blocks from locally uniform subdomains in the middle of the matrix, and smaller blocks---or indeed $1 \times 1$ blocks---near the boundary. 

%% Toeplitz matrices and generating functions 
To build an effective preconditioner and investigate its properites, we have to take full advantage of these SPD Toeplitz blocks. Toeplitz matrices have many unique properties that give rise to efficient algorithms (see for example \cite{toeplitz}). For our purposes we focus on their connection to functions in the Wiener class. This will allow us to take our problem from matrix operator theory to function theory. Suppose we have a singly infinite, symmetric Toeplitz matrix
\begin{equation*}
	T = \begin{pmatrix}
		t_0 & t_1 & t_2 & \\
		t_1 & t_0 & t_1 &  \ddots \\
		t_2 & t_1 & t_0 & \ddots  \\
		 & \ddots & \ddots & \ddots  \\
	\end{pmatrix}.
\end{equation*}
Assume $\sum_{k=-\infty}^{\infty} |t_k| <\infty$. Then the function $t(z) = \sum_{k=-\infty}^{\infty} t_k z^k$ is real, positive, and in the Wiener class for $|z| = 1$. It will be convenient to define the corresponding truncated function for a finite subsection of the infinite matrix: 
\begin{definition}
	The $m \times m$ finite subsection of the singly infinite matrix $T$ is denoted $T_m$ and defined as
	\begin{equation*}
				T_m = \begin{pmatrix}
			t_0 & t_1 & \cdots & t_{m-1} \\
			t_1 & t_0 & \cdots & t_{m-2} \\
			\vdots & \vdots & \ddots & \vdots \\
			t_{m-1} & t_{m-2} & \cdots & t_0 
		\end{pmatrix}.
	\end{equation*}
	Similarly this matrix induces a function from the truncated series, $t_m(z) = \sum_{k=-(m-1)}^{m-1} t_k z^k$. 
\end{definition}

Previous work on Toeplitz systems offers a few options for circulant preconditioners. Although their construction differs, the spectrum of the preconditioned systems are asymptotically the same \cite{Chan_89}. We use the construction given by Bini and Benedetto \cite{Bini}. Given a symmetric Toeplitz matrix $T$ we build a Hankel correction, $H$ where 
\begin{equation*}
	T = \begin{pmatrix}
		t_0 & t_1 & t_2 & \cdots &t_{n-2}& t_{n-1} \\
		t_1 & t_0 & t_1 &  \cdots &t_{n-3}& t_{n-2} \\
		t_2 & t_1 & t_0 & \cdots &t_{n-4}& t_{n-3} \\
		\vdots & \vdots & \vdots & \ddots&\vdots & \vdots \\
		t_{n-2} & t_{n-3} & t_{n-4} & \cdots &t_0 & t_1 \\
		t_{n-1} & t_{n-2} & t_{n-3} & \cdots & t_1 & t_0 
	\end{pmatrix}
	\Hank = \begin{pmatrix}
		t_2 & t_3 & t_4 & \cdots & t_{n-1} & 0 & 0 \\
		t_3 & t_4 & t_5 & \cdots  & 0 & 0 & 0 \\
		t_4 & t_5 & t_6 & \cdots & 0 & 0 & t_{n-1} \\
		\vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
		0 & 0 & 0 & \cdots & t_5 & t_4 & t_3 \\
		0 & 0 & t_{n-1} & \cdots & t_4 & t_3 & t_2
	\end{pmatrix}.
\end{equation*}
Then Bini and Benedetto's preconditioner is defined as $\ptau = T - H$. We summarize the important properties of $\ptau$ (see \cite{Bini} for details):
\begin{itemize}
	\item $\ptau$ is a circulant matrix
	\item $\ptau$ can be applied in $n \log n$ time 
	\item $\ptau$ is diagonalized by the discrete sine transform-I matrix 
	\item Each eigenvalue of $\ptau$ can be written as the truncated function $t_m$ evaluated somewhere on the unit circle, IE $\lambda_k(\ptau) = t_m(z_k)$ where $|z_k| = 1$.
\end{itemize}
These preconditioner can also be thought of as coming from the kernel of a displacement operator. This framework is useful for generating yet other circulant preconditioners, see \cite{Kailath}. 
% boundaries are the problem always (not infinite, block division)}
% Hankel matrices
% circulant and DFT/FFT (displacement kernel's)
% discrete convolution for exact solution and the boundary problem 

\section{Our Preconditioner}
In this section we set forth the properties we require from a preconditioner, how we use $\ptau$ in building our preconditioner, and how to build and apply our preconditioner efficiently.

A good preconditioner for an iterative method must in general decrease the total number of iterations without increasing the cost of a single iteration. We borrow Kailath's \cite{Kailath} criteria for preconditioners, though similar criteria has been established since Bini and Benedetto \cite{Bini}:
\begin{enumerate}
	\item Complexity of constructing  applying $\ptau$ should be $\bigOh (m \log m)$.
	\item A linear system with $\ptau$ should be solved in $ \bigOh (m \log m)$ operations.
	\item The spectrum of $\ptau^{-1} \A$ should be clustered around 1
\end{enumerate}
We can make this last point more precise. 
\begin{definition}[Eigenvalue Clustering] 
	For any $\varepsilon > 0$ we say the eigenvalues of a matrix $\ptau^{-1} \A_m$ are clustered around $1$ if there exists $N_1$ and $N_2$ such that for all $m > N_1$ there are at most $N_2$ eigenvalues of $\ptau^{-1} \A_m$ that do not lie within $ [1-\varepsilon, 1+\varepsilon]$.
\end{definition}
The use of circulant preconditioners for Toeplitz systems originates from \cite{Chan_Strang}. Kailath showed how both Strang and Chan type preconditioners come from the kernel of displacement operators, they further detail eight specific preconditioners for each form of the discrete sine and cosine transforms. \todo[inline]{apply in n log n time}

In our numerical results we use type TODO, discussed in \cite{Bini}. Though the results could be generalized to all eight forms. An important fact that we will use later:
\todo[inline]{eigenvalues as points on function }
$\A$ is Toeplitz block, $\Hank$ is ``Hankel Correction"
\begin{align*}
	\A = \begin{bmatrix}
		a_0 & a_1 & a_2 & \cdots &a_{n-2}& a_{n-1} \\
		a_1 & a_0 & a_1 &  \cdots &a_{n-3}& a_{n-2} \\
		a_2 & a_1 & a_0 & \cdots &a_{n-4}& a_{n-3} \\
		\vdots & \vdots & \vdots & \ddots&\vdots & \vdots \\
		a_{n-2} & a_{n-3} & a_{n-4} & \cdots &a_0 & a_1 \\
		a_{n-1} & a_{n-2} & a_{n-3} & \cdots & a_1 & a_0 
	\end{bmatrix}
	\Hank = \begin{bmatrix}
		a_2 & a_3 & a_4 & \cdots & a_{n-1} & 0 & 0 \\
		a_3 & a_4 & a_5 & \cdots  & 0 & 0 & 0 \\
		a_4 & a_5 & a_6 & \cdots & 0 & 0 & a_{n-1} \\
		\vdots & \vdots & \vdots & \cdots & \vdots & \vdots & \vdots \\
		0 & 0 & 0 & \cdots & a_5 & a_4 & a_3 \\
		0 & 0 & a_{n-1} & \cdots & a_4 & a_3 & a_2
	\end{bmatrix}
\end{align*}
$\ptau = \A-\Hank$


We'll also utilize the common assumptions that $ a(z) = \sum_{k=-\infty}^{\infty} |a_k| <\infty$ and $a(z) > 0$ for each Toeplitz block. 

To apply the $\tau$ preconditioner to our adaptive mesh we can think first of a block construction, 
 (explicit) Identify Toeplitz blocks $\A_j$, Build Hankel correction $\Hank_j$, Construct little $\ptau_j = A_j - \Hank_j$ . Assemble big $\mathcal{T} = \begin{bmatrix}
		\ptau_1 &&& \\ & \ptau_2 && \\ && \ddots & \\ &&& \ptau_m
	\end{bmatrix}$

To apply it $m \log m$ instead,  (implicit)
Get sizes of Toeplitz blocks $n_j$, calculate  $\lambda_i = c_i [\DST \t]_i$ for $1 \leq i \leq n_j$, apply $\DST \Lambda^{-1} \DST$.

\begin{itemize}
	\item story of many
	\item SPSD with SPSD A
	\item how it works w multigrid
\end{itemize}

\section{Theoretical Results} 
% notation table ?
% 1x1 blocks consideration 
Story: we know how this works on one block, what about block diagonal, what about with things happening outside of block diagonal? 
\subsection{Eigenvalue Bounds}
\begin{lemma}[Weyl's Inequality] \\ Let $M$ and $E$ be Hermitian $n \times n$ matrices. Then for $A := M + E$ we have 
	$$ | \lambda_k(A) - \lambda_k(M) | \leq ||E||_2 \ , 1 \leq k \leq n.$$
	That is the eigenvalues of $A$ are at most $||E||_2$ away from the eigenvalues of $M$. 
\end{lemma}
\subsubsection{Kailath-Olshevsky Proof rewritten}
Fix $\varepsilon > 0$. 
Assumptions:
\begin{enumerate}
	\item Generating function is in the Wiener Class, $$a(z) = \sum_{k = -\infty}^{\infty} a_k z^k, \  \sum_{k = -\infty}^{\infty} |a_k|< \infty.$$
	\item Generating function is bounded away from zero on unit circle, $$a(z) > 2 \varepsilon, \ |z|=1.$$
\end{enumerate}

\begin{lemma}
	Let $a_m(z)$ be the truncated generating function with $2m-1$ terms, $\sum_{k = -(m-1)}^{m-1} a_k z^k$.
	Then for each $\lambda_k(\Sq(A))$ there exists $z_k$ on the unit circle such that $\lambda_k = a_m(z_k)$. 
\end{lemma}

\begin{lemma}
	Choose $m$ and $N <m$ big enough so that $\sum_{N+1}^{\infty} |a_k| < \varepsilon$. Then assumption 2 implies that $a_m(z)$ is positive on the unit circle. 
\end{lemma}
\begin{proof}
	First notice $\varepsilon > \sum_{N+1}^{\infty} |a_k| > \sum_{m}^{\infty} |a_k|$. 
	Now
	\begin{align*}
		a(z) &=  a_m(z) + \sum_{-\infty}^{-m} a_k z^k + \sum_{m}^{\infty} a_k z^k \\ 
		&\implies 	a_m(z) =  a(z) - \sum_{-\infty}^{-m} a_k z^k - \sum_{m}^{\infty} a_k z^k \\ 
		&\implies a(z) - 2 \varepsilon < a_m(z) \\
		&\ 0 < a(z) - 2 \varepsilon < a_m(z)
	\end{align*}
\end{proof}

\begin{corollary}
	The matrices $\Sq(A_m)$ and $\Sq(A_m)^{-1}$ are positive definite.
\end{corollary}

First we present the proof for a single Toeplitz matrix/block, adapted from \cite{Kailath}. This will be used in the proof of the full matrix spectral clustering. 
\todo[inline]{Lemma statement }
\begin{align}
	\Sq(A) &= A + H + B \\
	A &= \Sq(A) - (H+B)
\end{align}
Where $A$ is Toeplitz (given), $H$ is Hankel, and $B$ is `border' matrix, at most nonzero in exterior rows and columns. 
Thus $$\Sq(A)^{-1} A = I - \Sq(A)^{-1} (H+B).$$
So it suffices to show the spectrum of $\Sq(A)^{-1} (H+B)$ is clustered around zero. \\
Let $\varepsilon > 0 $ and choose $N$ such that $\sum_{N+1}^{\infty} |a_k| < \varepsilon$. We can then split $H+B$ into the sum of a low-rank matrix $A_{lr}$ and a small norm matrix $A_{sn}$.  Here $A_{lr}$ contains the diagonals with entries $a_0, \dots, a_N$. Let $s := \text{rank}(A_{lr}) << m$. Now $A_{sn} := (H+B) - A_{lr}$ is a hermitian $m \times m$ matrix with at most two copies of $a_{N+1}, \dots, a_m$ in each row/column. Thus $||A_{sn}||_2 = \sqrt{||A_{sn}||_1 ||A_{sn}||_{\infty}} = ||A_{sn}||_1 < 2 \varepsilon$.  Hence by Weyl's Inequality at least $m-s$ of the eigenvalues of $H+B$ are clustered within $2 \varepsilon$ of zero. 

Now we use the min-max theorem to bound the eigenvalues of $\Sq(A)^{-1} (H+B)$. 
\begin{align*}
	\lambda_k ( \Sq(A)^{-1} (H+B)) &= \min_{\dim V=k} \max_{x \in V} \left(  \frac{((H+B)x,x)}{(\Sq(A)x,x)}\right) \\
	&\leq   \min_{\dim V =k} \left[ \max_{x \in V} \left( \frac{((H+B)x,x)}{(x,x)} \right)  \max_{x \in V} \left( \frac{(x,x)}{(\Sq(A)x,x)} \right) \right] \\
	&\leq \left[  \min_{\dim V =k}  \max_{x \in V} \left( \frac{((H+B)x,x)}{(x,x)} \right)  \right] \max_{x \in \R^n} \left( \frac{(x,x)}{(\Sq(A)x,x)} \right)  \\
	&= \lambda_k(H+B)   \max_{x \in \R^n} \left( \frac{(x,x)}{(\Sq(A)x,x)} \right)  \\
	&\leq \lambda_k(H+B)  \frac{1}{\lambda_{\min}(\Sq(A))} \\
	&= \lambda_k(H+B)  \frac{1}{a_m(z_{\min})} \\ 
	&\leq \lambda_k(H+B)  \frac{1}{\min_{|z|=1} a_m(z)} 
\end{align*}

Can be simplified with $B = \zero$.
Actual condition: $a(z) > 2 \varepsilon$. 

\subsection{Full Matrix Proof}
\subsubsection{setup}
A single block preconditioner is $\tau$ the block diagonal preconditioner is $\Tau$.

On a single block we write $\tau = \A - \Hank$, but for the full adaptive matrix $\A$ includes off diagonal blocks. Denote the diagonal (Toeplitz blocks) as $\A_D$ and everything else $\A_E$ so that $$\A = \A_D + \A_E + \offd$$. And thus the splitting as in \cite{Kailath} is expressed $\A_D = \Tau + H$ and $\A = \A_E + \offd + \Tau + \Hank$. So
\begin{equation}\label{decomp}
	\Tau^{-1} \A = \Tau^{-1}(\Tau + \Hank + \A_E + \offd) = I +\Tau^{-1}\Hank + \Tau^{-1}\A_E  +\Tau^{-1}\offd
\end{equation}
\subsubsection{Proof}
It suffices to show that $\Tau^{-1}\Hank$, $\Tau^{-1}\offd$ and $\Tau^{-1}\A_E$ have spectra clustered around zero. 
First notice that $\Tau^{-1} \Hank$ is block diagonal and the spectrum of each block can be characterized using the former proof on each block. 

\todo[inline]{since we don't really choose block size in practice the actual block size dictates the size of $\varepsilon$. Over all the blocks we can take the max $\varepsilon$ for a uniform bound, but many will be clustered tighter than that. Supports argument that bigger Toeplitz blocks = better clustering}

Assume the off-diagonal-by-one blocks are low-rank. Let $C$ be such a block with dimensions $n_C \times n_C$ and rank $r_C << n_C$. Using the SVD we can split $C$ as $$ C = \left( \sum_{i=1}^{r_{C}} \sigma_i^{(C)} \u_i ^{(C)}\v_i^{(C)}* \right) + \left(  \sum_{i=r_{C}+1}^{n_{C}} \sigma_i^{(C)} \u_i^{(C)} \v_i^{(C)}*  \right). $$ 
With a slight abuse of notation, we can embed this decomposition in the appropriate ``off-diagonal'' position of an $m \times m$ matrix. Doing this for all such off-diagonal blocks we write
\begin{align*}
	B &= \sum_{C \in \text{off-diag}} \left[ \left( \sum_{i=1}^{r_{C}} \sigma_i^{(C)} \u_i ^{(C)}\v_i^{(C)}* \right) + \left(  \sum_{i=r_{C}+1}^{n_{C}} \sigma_i^{(C)} \u_i^{(C)} \v_i^{(C)}*  \right) \right]  \\
	&= \left( \sum_{i=1}^{r_{\offd}} \sigma_i \u_i \v_i* \right) + \left(  \sum_{i=r_{\offd}+1}^{n_{\offd}} \sigma_i \u_i \v_i*  \right) 
\end{align*}
where $r_{\offd} = \max_{C \in \text{off-diag}} r_C$.

We additionally split $\Hank$ by separating the anti-diagonals with coefficients $a_0, \dots, a_N$ and the anti-diagonals comprising of $a_{N+1}, \dots a_m$. So we have two splittings, 
\begin{align*} 
	\offd &= \left( \sum_{i=1}^{r_{\offd}} \sigma_i \u_i \v_i* \right) + \left(  \sum_{i=r_{\offd}+1}^{n_{\offd}} \sigma_i \u_i \v_i*  \right) \\
	\Hank &= \Hank|_{a_{0},\dots,a_N} + \Hank|_{a_{N+1},\dots,a_m}.
\end{align*}
The first term in each sum can be thought of as our `low-rank' equivalent from before and similarly the second term is our `small-norm' summand. \todo[inline]{Bound on number of off diagonal blocks} 

Finally we can make the splitting $\A = \A_{SN} + \A_{LR}$ where
\begin{align*}
	\A_{SN} &= \Hank|_{a_{N+1},\dots,a_m} + \sum_{i=r_{\offd}+1}^{n_{\offd}} \sigma_i \u_i \v_i* +A_E \\
	\A_{LR} &= \Hank|_{a_{0},\dots,a_N} + \sum_{i=1}^{r_{\offd}} \sigma_i \u_i \v_i*.
\end{align*}
$\A_{LR}$ represent outliers, IE $s := \text{rank}(\A_{LR}) \leq N + r_{\offd}$ bounds the number of outliers. \todo[inline]{Is the N part of this bound true? 2N?} So the work is showing $|| \Tau^{-1}\A_{SN}||_2 \leq \varepsilon$. Define $\tilde{\offd} = \sum_{i=r_{\offd}+1}^{n_{\offd}} \sigma_i \u_i \v_i* $ and $\tilde{\Hank} = \Hank|_{a_{N+1},\dots,a_m}$, so that $\A_{SN} = \tilde{\Hank} + \tilde{\offd} + \A_E$. 
\begin{align*}
	|| \Tau^{-1}\A_{SN}||_2 &\leq ||\Tau^{-1} \tilde{\Hank}||_2 + ||\Tau^{-1} \tilde{\offd}||_2 +||\Tau^{-1} \A_E ||_2
\end{align*}
We can bound $||\Tau^{-1} \tilde{\Hank}||_2$ as in \cite{Kailath}. We can bound $||\Tau^{-1} \A_E||_2$ with Weyl's inequality:
\begin{equation*}
	||\Tau^{-1} \A_E||_2 \leq ||\Tau^{-1}||_2 ||\A_E||_2 =\sigma_{\max}(\Tau^{-1}) \sigma_{\max}(\A_E) = \frac{ \sigma_{\max}(\A_E)}{\lambda_{\min}(\Tau)}.
\end{equation*}
Finally we bound $||\Tau^{-1} \tilde{\offd}||_2$.
\begin{align*}
	\lambda_k ( \Tau^{-1} \tilde{\offd}) &= \min_{\dim V=k} \max_{x \in V} \left(  \frac{(\tilde{\offd}x,x)}{(\Tau x,x)}\right) \\
	&\leq   \min_{\dim V =k} \left[ \max_{x \in V} \left( \frac{(\tilde{\offd} x,x)}{(x,x)} \right)  \max_{x \in V} \left( \frac{(x,x)}{(\Tau x,x)} \right) \right] \\
	&\leq \left[  \min_{\dim V =k}  \max_{x \in V} \left( \frac{(\tilde{\offd} x,x)}{(x,x)} \right)  \right] \max_{x \in \R^n} \left( \frac{(x,x)}{(\Tau x,x)} \right)  \\
	&= \lambda_k(\tilde{\offd})   \max_{x \in \R^n} \left( \frac{(x,x)}{(\Tau x,x)} \right)  \\
	&\leq \lambda_k(\tilde{\offd})  \frac{1}{\lambda_{\min}(\Tau)} \\
	&= \lambda_k(\tilde{\offd})  \min_{n \in n_k} \min_{1 \leq i \leq n} \frac{\sin(\frac{\pi i}{n+1})}{\sum_{j=1}^n t_j \sin(\frac{\pi i j }{n+1})}
\end{align*}
Since $\tilde{\offd}$ made of blocks that have form $\sum_{i=r_{\offd}+1}^{n_{\offd}} \sigma_i \u_i \v_i*$ what can we say about $\lambda_k$?  

\begin{itemize}
	\item numerical test confirming off-diag low rank
	\item Explanation and tests showing off-off-diag are small norm 
	\item technically lots of $ 1 \times 1$ blocks at boundaries, these get jacobi inverse treatment so are clustered around 1 
	\item Comment - all problems come from boundaries
	\item Extend proof to different kinds of circulant preconditioner
\end{itemize}

\section{Numerical Results}
\begin{itemize}
	\item enough info to reproduce 
	\item Single block clustering
	\item Adaptive clustering (what happens to smallest eigenvalue?)
	\item behavior for different $\alpha$
	\item Verify assumptions from proof
	\item convergence of solving with PCG (superlinear convergence)
\end{itemize}

\section{Conclusion}
Future work: how to build adaptive mesh to increase block size, other circulant preconditioners, tensor preconditioners, higher dimension domain, mixed precision 

\bibliographystyle{siamplain}
\bibliography{references}

\end{document}
